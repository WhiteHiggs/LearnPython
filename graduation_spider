#-*-coding:utf8-*-
#用来爬取某大学某专业的毕业生去向，数据存入info.txt
import requests
import re
import codecs
# import sys
# reload(sys)
# sys.setdefaultencoding("gbk")

class spider(object):
    def __init__(self):
        print u'开始爬取内容。。。'
#changepage用来生产不同页数的链接
    def changepage(self,ID_num):
        login_data = { 'id':'','id1':'', 'start1':'\xb2\xe9\xd1\xaf'}
        login_data['id'] = ID_num
        return login_data
#getsource用来获取网页源代码
    def getsource(self,url,login_data):
        myheaders = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.154 Safari/537.36'}
        html_post = requests.post(url, data = login_data, headers = myheaders)
        html_post.encoding = 'gbk'
        return html_post.text
#getinfo用来从每个人的信息中提取出我们需要的信息
    def getinfo(self,field,raw_indi):
        info = {}
        info['year'] = raw_indi[0]
        subtr = raw_indi[1].split()
        info['ID'] = subtr[0]
        info['name'] = re.findall(':</b>(.*)',subtr[1],re.S)[0]
        info['college'] =  re.findall(':</b>(.*)',subtr[2],re.S)[0]
        info['subject'] = re.findall(':</b>(.*)',subtr[3],re.S)[0]
        info['destination'] = raw_indi[-1]
        return info

#saveinfo用来保存结果到info.txt文件中
    def saveinfo(self,classinfo):
        f = codecs.open('info.txt','w','utf-8')
        for each in classinfo:
            f.writelines(each['year'] + ' ' + each['name']+ ' ' +each['ID'] + ' ' + each['subject']+ ' '+ each['destination'] + ' ' + '\n')
        f.close()



if __name__ == '__main__':

    classinfo = []
    url = 'http://210.42.38.45/th/XXXXXXXXXX'
    gradspider = spider()
    f_data = open('ID.txt','r')
    ID_num = f_data.readlines()
    # ID_num = ['2011109317\n']

    for n in ID_num:
        num = n[0:-1]
        print u'正在处理页面：' + num
        login_data = gradspider.changepage(num)
        html = gradspider.getsource(url,login_data)
        field = re.findall('<td width="676" align="left" valign="top" rowspan="2">(.*?)<td width="307" align="left" valign="top">',html,re.S)
        raw_indi = re.findall('</b>(.*?)<hr>',field[0],re.S)
        if raw_indi:
            info = gradspider.getinfo(field,raw_indi)
            classinfo.append(info)
        else:
            pass
    gradspider.saveinfo(classinfo)
